[
["index.html", "Intro to R-Spatial for Healthy Places Background", " Intro to R-Spatial for Healthy Places Marynia Kolak 2021-08-24 Background This suite of tutorials was developed for a workshop at the 2021 R-Medicine Conference by the Health Regions &amp; Policies Lab at the University of Chicago. A basic understanding of R is assumed. This workshop requires several packages, which can be installed from CRAN: install.packages(&quot;sf&quot;, &quot;tmap&quot;, &quot;tidygeocoder&quot;) For Mac users, check out https://github.com/r-spatial/sf for additional tips if you run into errors when installing the sf package. Using homebrew to install gdal usually fixes any remaining issues. "],
["01-intro.html", "1 Introduction 1.1 Load Spatial Data 1.2 Non-Spatial &amp; Spatial Views 1.3 Spatial Data Structure 1.4 Exploring Coordinate Reference Systems 1.5 Refine Basic Map 1.6 Arrange multiple maps 1.7 Interactive Mode 1.8 Overlay Zip Code Boundaries More Resources", " 1 Introduction In the workshop, we learned about: What is Spatial Data? What is the sf framework for R? To delve in further, let’s see some spatial data in action. We’ll work with the sf library first. library(sf) 1.1 Load Spatial Data Chi_tracts = st_read(&quot;data/geo_export_aae47441-adab-4aca-8cb0-2e0c0114096e.shp&quot;) ## Reading layer `geo_export_aae47441-adab-4aca-8cb0-2e0c0114096e&#39; from data source ## `/Users/maryniakolak/code/Intro2RSpatialMed/data/geo_export_aae47441-adab-4aca-8cb0-2e0c0114096e.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 801 features and 9 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -87.94025 ymin: 41.64429 xmax: -87.52366 ymax: 42.02392 ## CRS: 4326 1.2 Non-Spatial &amp; Spatial Views head(Chi_tracts) ## Simple feature collection with 6 features and 9 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -87.68822 ymin: 41.72902 xmax: -87.62394 ymax: 41.87455 ## CRS: 4326 ## commarea commarea_n countyfp10 geoid10 name10 namelsad10 notes ## 1 44 44 031 17031842400 8424 Census Tract 8424 &lt;NA&gt; ## 2 59 59 031 17031840300 8403 Census Tract 8403 &lt;NA&gt; ## 3 34 34 031 17031841100 8411 Census Tract 8411 &lt;NA&gt; ## 4 31 31 031 17031841200 8412 Census Tract 8412 &lt;NA&gt; ## 5 32 32 031 17031839000 8390 Census Tract 8390 &lt;NA&gt; ## 6 28 28 031 17031838200 8382 Census Tract 8382 &lt;NA&gt; ## statefp10 tractce10 geometry ## 1 17 842400 POLYGON ((-87.62405 41.7302... ## 2 17 840300 POLYGON ((-87.68608 41.8229... ## 3 17 841100 POLYGON ((-87.62935 41.8528... ## 4 17 841200 POLYGON ((-87.68813 41.8556... ## 5 17 839000 POLYGON ((-87.63312 41.8744... ## 6 17 838200 POLYGON ((-87.66782 41.8741... plot(Chi_tracts) 1.3 Spatial Data Structure str(Chi_tracts) ## Classes &#39;sf&#39; and &#39;data.frame&#39;: 801 obs. of 10 variables: ## $ commarea : Factor w/ 77 levels &quot;1&quot;,&quot;10&quot;,&quot;11&quot;,..: 39 55 28 25 26 21 62 49 74 75 ... ## $ commarea_n: num 44 59 34 31 32 28 65 53 76 77 ... ## $ countyfp10: Factor w/ 1 level &quot;031&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ geoid10 : Factor w/ 801 levels &quot;17031010100&quot;,..: 785 767 772 773 756 751 584 513 684 34 ... ## $ name10 : Factor w/ 801 levels &quot;1001&quot;,&quot;1002&quot;,..: 782 764 769 770 753 748 545 443 663 266 ... ## $ namelsad10: Factor w/ 801 levels &quot;Census Tract 1001&quot;,..: 782 764 769 770 753 748 545 443 663 266 ... ## $ notes : Factor w/ 7 levels &quot;Half in CA 64 (Midway Airport)&quot;,..: NA NA NA NA NA NA NA NA NA NA ... ## $ statefp10 : Factor w/ 1 level &quot;17&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ tractce10 : Factor w/ 801 levels &quot;010100&quot;,&quot;010201&quot;,..: 785 767 772 773 756 751 584 513 684 34 ... ## $ geometry :sfc_POLYGON of length 801; first list element: List of 1 ## ..$ : num [1:243, 1:2] -87.6 -87.6 -87.6 -87.6 -87.6 ... ## ..- attr(*, &quot;class&quot;)= chr &quot;XY&quot; &quot;POLYGON&quot; &quot;sfg&quot; ## - attr(*, &quot;sf_column&quot;)= chr &quot;geometry&quot; ## - attr(*, &quot;agr&quot;)= Factor w/ 3 levels &quot;constant&quot;,&quot;aggregate&quot;,..: NA NA NA NA NA NA NA NA NA ## ..- attr(*, &quot;names&quot;)= chr &quot;commarea&quot; &quot;commarea_n&quot; &quot;countyfp10&quot; &quot;geoid10&quot; ... st_crs(Chi_tracts) ## Coordinate Reference System: ## User input: 4326 ## wkt: ## GEOGCS[&quot;WGS84(DD)&quot;, ## DATUM[&quot;WGS84&quot;, ## SPHEROID[&quot;WGS84&quot;,6378137.0,298.257223563]], ## PRIMEM[&quot;Greenwich&quot;,0.0], ## UNIT[&quot;degree&quot;,0.017453292519943295], ## AXIS[&quot;Geodetic longitude&quot;,EAST], ## AXIS[&quot;Geodetic latitude&quot;,NORTH]] 1.4 Exploring Coordinate Reference Systems Chi_tracts.moll &lt;- st_transform(Chi_tracts, crs = &quot;+proj=moll&quot;) plot(st_geometry(Chi_tracts.moll), border = &quot;gray&quot;, lwd = 2, main = &quot;Mollweide&quot;, sub=&quot;preserves areas&quot;) st_crs(Chi_tracts.moll) ## Coordinate Reference System: ## User input: +proj=moll ## wkt: ## PROJCS[&quot;unnamed&quot;, ## GEOGCS[&quot;WGS 84&quot;, ## DATUM[&quot;unknown&quot;, ## SPHEROID[&quot;WGS84&quot;,6378137,298.257223563]], ## PRIMEM[&quot;Greenwich&quot;,0], ## UNIT[&quot;degree&quot;,0.0174532925199433]], ## PROJECTION[&quot;Mollweide&quot;], ## PARAMETER[&quot;central_meridian&quot;,0], ## PARAMETER[&quot;false_easting&quot;,0], ## PARAMETER[&quot;false_northing&quot;,0]] Chi_tracts.54019 = st_transform(Chi_tracts, 54019) plot(st_geometry(Chi_tracts.54019), border = &quot;gray&quot;, lwd = 2, main = &quot;Winkel&quot;, sub=&quot;minimal distortion&quot;) st_crs(Chi_tracts.54019) ## Coordinate Reference System: ## User input: EPSG:54019 ## wkt: ## PROJCS[&quot;World_Winkel_II&quot;, ## GEOGCS[&quot;GCS_WGS_1984&quot;, ## DATUM[&quot;WGS_1984&quot;, ## SPHEROID[&quot;WGS_84&quot;,6378137.0,298.257223563]], ## PRIMEM[&quot;Greenwich&quot;,0.0], ## UNIT[&quot;Degree&quot;,0.0174532925199433]], ## PROJECTION[&quot;Winkel_II&quot;], ## PARAMETER[&quot;False_Easting&quot;,0.0], ## PARAMETER[&quot;False_Northing&quot;,0.0], ## PARAMETER[&quot;Central_Meridian&quot;,0.0], ## PARAMETER[&quot;Standard_Parallel_1&quot;,50.45977625218981], ## UNIT[&quot;Meter&quot;,1.0], ## AUTHORITY[&quot;Esri&quot;,&quot;54019&quot;]] Chi_tracts.3435 &lt;- st_transform(Chi_tracts, 3435) st_crs(Chi_tracts.3435) ## Coordinate Reference System: ## User input: EPSG:3435 ## wkt: ## PROJCS[&quot;NAD83 / Illinois East (ftUS)&quot;, ## GEOGCS[&quot;NAD83&quot;, ## DATUM[&quot;North_American_Datum_1983&quot;, ## SPHEROID[&quot;GRS 1980&quot;,6378137,298.257222101, ## AUTHORITY[&quot;EPSG&quot;,&quot;7019&quot;]], ## TOWGS84[0,0,0,0,0,0,0], ## AUTHORITY[&quot;EPSG&quot;,&quot;6269&quot;]], ## PRIMEM[&quot;Greenwich&quot;,0, ## AUTHORITY[&quot;EPSG&quot;,&quot;8901&quot;]], ## UNIT[&quot;degree&quot;,0.0174532925199433, ## AUTHORITY[&quot;EPSG&quot;,&quot;9122&quot;]], ## AUTHORITY[&quot;EPSG&quot;,&quot;4269&quot;]], ## PROJECTION[&quot;Transverse_Mercator&quot;], ## PARAMETER[&quot;latitude_of_origin&quot;,36.66666666666666], ## PARAMETER[&quot;central_meridian&quot;,-88.33333333333333], ## PARAMETER[&quot;scale_factor&quot;,0.999975], ## PARAMETER[&quot;false_easting&quot;,984250.0000000002], ## PARAMETER[&quot;false_northing&quot;,0], ## UNIT[&quot;US survey foot&quot;,0.3048006096012192, ## AUTHORITY[&quot;EPSG&quot;,&quot;9003&quot;]], ## AXIS[&quot;X&quot;,EAST], ## AXIS[&quot;Y&quot;,NORTH], ## AUTHORITY[&quot;EPSG&quot;,&quot;3435&quot;]] plot(st_geometry(Chi_tracts.3435), border = &quot;gray&quot;, lwd = 2, main = &quot;NAD83 / Illinois East (ftUS)&quot;, sub=&quot;topo mapping &amp; survey use&quot;) Chi_tracts.Hawaii = st_transform(Chi_tracts, 102114) plot(st_geometry(Chi_tracts.Hawaii), border = &quot;gray&quot;, lwd = 2, main = &quot;Old Hawaiian UTM Zone 4N&quot;, sub=&quot;wrong projection!&quot;) 1.5 Refine Basic Map library(tmap) tm_shape(Chi_tracts) + tm_borders(alpha=0.5) tm_shape(Chi_tracts) + tm_fill(col = &quot;gray90&quot;) + tm_borders(alpha=0.2, col = &quot;gray10&quot;) + tm_scale_bar(position = (&quot;left&quot;), lwd = 0.8) + tm_layout(frame = F) Check out https://rdrr.io/cran/tmap/man/tm_polygons.html for more ideas. 1.6 Arrange multiple maps tracts.4326 &lt;- tm_shape(Chi_tracts) + tm_fill(col = &quot;gray90&quot;) + tm_layout(frame = F, title = &quot;EPSG 4326&quot;) tracts.54019 &lt;- tm_shape(Chi_tracts.54019) + tm_fill(col = &quot;gray90&quot;) + tm_layout(frame = F, title = &quot;EPSG 54019&quot;) tmap_arrange(tracts.4326, tracts.54019) 1.7 Interactive Mode tmap_mode(&quot;view&quot;) ## tmap mode set to interactive viewing tm_shape(Chi_tracts) + tm_fill(col = &quot;gray90&quot;) + tm_borders(alpha=0.2, col = &quot;gray10&quot;) + tm_scale_bar(position = (&quot;left&quot;), lwd = 0.8) + tm_layout(frame = F) ## Warning in `$.crs`(gm$shape.master_crs, &quot;proj4string&quot;): CRS uses proj4string, ## which is deprecated. ## Warning in `$.crs`(crs, &quot;proj4string&quot;): CRS uses proj4string, which is deprecated. tm_shape(Chi_tracts) + tm_fill(col = &quot;gray90&quot;, alpha = 0.5) + tm_borders(alpha=0.2, col = &quot;gray10&quot;) + tm_scale_bar(position = (&quot;left&quot;), lwd = 0.8) + tm_layout(frame = F) ## Warning in `$.crs`(gm$shape.master_crs, &quot;proj4string&quot;): CRS uses proj4string, ## which is deprecated. ## Warning in `$.crs`(crs, &quot;proj4string&quot;): CRS uses proj4string, which is deprecated. tmap_mode(&quot;plot&quot;) ## tmap mode set to plotting 1.8 Overlay Zip Code Boundaries First, we read in zip code boundaries. This data was downloaded directly from the City of Chicago Data Portal as a shapefile. Chi_Zips = st_read(&quot;data/geo_export_54bc15d8-5ef5-40e4-8f72-bb0c6dbac9a5.shp&quot;) ## Reading layer `geo_export_54bc15d8-5ef5-40e4-8f72-bb0c6dbac9a5&#39; from data source ## `/Users/maryniakolak/code/Intro2RSpatialMed/data/geo_export_54bc15d8-5ef5-40e4-8f72-bb0c6dbac9a5.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 61 features and 4 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -87.94011 ymin: 41.64454 xmax: -87.52414 ymax: 42.02304 ## CRS: 4326 Next, we layer the new shape in – on top of the tracts. We use a thicker border, and try out a new color. Experiment! ## FIRST LAYER: CENSUS TRACT BOUNADRIES tm_shape(Chi_tracts.3435) + tm_fill(col = &quot;gray90&quot;) + tm_borders(alpha=0.2, col = &quot;gray10&quot;) + ## SECOND LAYER: ZIP CODE BOUNDARIES WITH LABEL tm_shape(Chi_Zips) + tm_borders(lwd = 2, col = &quot;#0099CC&quot;) + tm_text(&quot;zip&quot;, size = 0.7) + ## MORE CARTOGRAPHIC STYLE tm_scale_bar(position = (&quot;left&quot;), lwd = 0.8) + tm_layout(frame = F) More Resources On spatial data basics &amp; sf: https://geocompr.robinlovelace.net/intro.html https://geodacenter.github.io/opioid-environment-toolkit/spatial-data-introduction.html On projections: https://desktop.arcgis.com/en/arcmap/10.3/guide-books/map-projections/projection-basics-for-gis-professionals.htm https://geocompr.robinlovelace.net/reproj-geo-data.html https://datacarpentry.org/organization-geospatial/03-crs/index.html On tmap: https://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.html https://geocompr.robinlovelace.net/adv-map.html "],
["02-choropleth.html", "2 Map Neighborhoods 2.1 Clean Attribute Data 2.2 Merge Spatial Data 2.3 Quantile Maps 2.4 Standard Deviation Maps 2.5 Jenks Maps 2.6 Integrate More Data 2.7 Thematic Map Panel 2.8 Write Data More Resources", " 2 Map Neighborhoods When considering the health of persons, we have to also consider the neighborhood environment. Sometimes this is looking at neighborhood level health outcomes, like premature mortality at the census tract scale, or cumulative COVID rates by zip code. Sometimes we’re interested in neighborhood factors like how poverty, access to affordable housing or healthy produce, or distance to nearest health provider, or pollution-emitting facility. These measurements of the “social determinants of health” at the neighborhood scale are increasingly urgent in modern public health thinking. In this module, we’ll learn about the basics of thematic mapping – known as choropleth mapping – to visualize neighborhood level health phenomena. 2.1 Clean Attribute Data Let’s consider COVID-19 cases by zip code in Chicago. We’ll upload and inspect a summary of cases from the Chicago Data Portal first: COVID &lt;- read.csv(&quot;data/COVID-19_Cases__Tests__and_Deaths_by_ZIP_Code.csv&quot;) head(COVID) ## ZIP.Code Week.Number Week.Start Week.End Cases...Weekly Cases...Cumulative ## 1 60603 39 09/20/2020 09/26/2020 0 13 ## 2 60604 39 09/20/2020 09/26/2020 0 31 ## 3 60611 16 04/12/2020 04/18/2020 8 72 ## 4 60611 15 04/05/2020 04/11/2020 7 64 ## 5 60615 11 03/08/2020 03/14/2020 NA NA ## 6 60603 10 03/01/2020 03/07/2020 NA NA ## Case.Rate...Weekly Case.Rate...Cumulative Tests...Weekly Tests...Cumulative ## 1 0 1107.3 25 327 ## 2 0 3964.2 12 339 ## 3 25 222.0 101 450 ## 4 22 197.4 59 349 ## 5 NA NA 6 9 ## 6 NA NA 0 0 ## Test.Rate...Weekly Test.Rate...Cumulative Percent.Tested.Positive...Weekly ## 1 2130 27853.5 0.0 ## 2 1534 43350.4 0.0 ## 3 312 1387.8 0.1 ## 4 182 1076.3 0.1 ## 5 14 21.7 NA ## 6 0 0.0 NA ## Percent.Tested.Positive...Cumulative Deaths...Weekly Deaths...Cumulative ## 1 0.0 0 0 ## 2 0.1 0 0 ## 3 0.2 0 0 ## 4 0.2 0 0 ## 5 NA 0 0 ## 6 NA 0 0 ## Death.Rate...Weekly Death.Rate...Cumulative Population Row.ID ## 1 0 0 1174 60603-39 ## 2 0 0 782 60604-39 ## 3 0 0 32426 60611-16 ## 4 0 0 32426 60611-15 ## 5 0 0 41563 60615-11 ## 6 0 0 1174 60603-10 ## ZIP.Code.Location ## 1 POINT (-87.625473 41.880112) ## 2 POINT (-87.629029 41.878153) ## 3 POINT (-87.620291 41.894734) ## 4 POINT (-87.620291 41.894734) ## 5 POINT (-87.602725 41.801993) ## 6 POINT (-87.625473 41.880112) Each row corresponds to a zip code at a differnent week. This data thus exists as a “long” format, which doesn’t work for spatial analysis. We need to convert to “wide” format, or at the very least, ensure that each zip code corresponds to one row. To simplify, let’s identify the last week of the dataset, and then subset the data frame to only show that week. We will be interested in the cumulative case rate. Following is one way of doing this – can you think of another way? Try out different approaches to test your R and “tidy” skills. ## How many weeks are in our dataset? range(as.numeric(COVID$Week.End)) ## [1] 1 31 ## Convert Week.End to numeric COVID$week_end &lt;- as.numeric(COVID$Week.End) ## Subset &amp; inspect to week 39. COVID.39 &lt;- subset(COVID, COVID$Week.Number == &quot;39&quot;) head(COVID.39) ## ZIP.Code Week.Number Week.Start Week.End Cases...Weekly Cases...Cumulative ## 1 60603 39 09/20/2020 09/26/2020 0 13 ## 2 60604 39 09/20/2020 09/26/2020 0 31 ## 36 60601 39 09/20/2020 09/26/2020 8 213 ## 37 60602 39 09/20/2020 09/26/2020 0 21 ## 41 60605 39 09/20/2020 09/26/2020 12 391 ## 66 60610 39 09/20/2020 09/26/2020 35 666 ## Case.Rate...Weekly Case.Rate...Cumulative Tests...Weekly Tests...Cumulative ## 1 0 1107.3 25 327 ## 2 0 3964.2 12 339 ## 36 54 1451.4 202 4304 ## 37 0 1688.1 27 460 ## 41 44 1420.8 291 7160 ## 66 90 1706.9 500 10680 ## Test.Rate...Weekly Test.Rate...Cumulative Percent.Tested.Positive...Weekly ## 1 2130 27853.5 0.0 ## 2 1534 43350.4 0.0 ## 36 1376 29328.8 0.0 ## 37 2170 36977.5 0.0 ## 41 1058 26018.4 0.0 ## 66 1281 27371.3 0.1 ## Percent.Tested.Positive...Cumulative Deaths...Weekly Deaths...Cumulative ## 1 0.0 0 0 ## 2 0.1 0 0 ## 36 0.0 1 6 ## 37 0.0 0 0 ## 41 0.1 1 3 ## 66 0.1 0 10 ## Death.Rate...Weekly Death.Rate...Cumulative Population Row.ID ## 1 0.0 0.0 1174 60603-39 ## 2 0.0 0.0 782 60604-39 ## 36 6.8 40.9 14675 60601-39 ## 37 0.0 0.0 1244 60602-39 ## 41 3.6 10.9 27519 60605-39 ## 66 0.0 25.6 39019 60610-39 ## ZIP.Code.Location week_end ## 1 POINT (-87.625473 41.880112) 30 ## 2 POINT (-87.629029 41.878153) 30 ## 36 POINT (-87.622844 41.886262) 30 ## 37 POINT (-87.628309 41.883136) 30 ## 41 POINT (-87.623449 41.867824) 30 ## 66 POINT (-87.63581 41.90455) 30 To clean our data a bit, we’ll just keep the zip code name, and cumulative case rate for the week of September 20th, 2020. COVID.39f &lt;- COVID.39[,c(&quot;ZIP.Code&quot;, &quot;Case.Rate...Cumulative&quot;)] head(COVID.39f) ## ZIP.Code Case.Rate...Cumulative ## 1 60603 1107.3 ## 2 60604 3964.2 ## 36 60601 1451.4 ## 37 60602 1688.1 ## 41 60605 1420.8 ## 66 60610 1706.9 2.2 Merge Spatial Data Next, let’s merge this data to our zip code master spatial file. Reload if necessary: library(sf) Chi_Zips = st_read(&quot;data/geo_export_54bc15d8-5ef5-40e4-8f72-bb0c6dbac9a5.shp&quot;) ## Reading layer `geo_export_54bc15d8-5ef5-40e4-8f72-bb0c6dbac9a5&#39; from data source ## `/Users/maryniakolak/code/Intro2RSpatialMed/data/geo_export_54bc15d8-5ef5-40e4-8f72-bb0c6dbac9a5.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 61 features and 4 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -87.94011 ymin: 41.64454 xmax: -87.52414 ymax: 42.02304 ## CRS: 4326 head(Chi_Zips) ## Simple feature collection with 6 features and 4 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -87.80649 ymin: 41.88747 xmax: -87.59852 ymax: 41.93228 ## CRS: 4326 ## objectid shape_area shape_len zip geometry ## 1 33 106052287 42720.04 60647 MULTIPOLYGON (((-87.67762 4... ## 2 34 127476051 48103.78 60639 MULTIPOLYGON (((-87.72683 4... ## 3 35 45069038 27288.61 60707 MULTIPOLYGON (((-87.785 41.... ## 4 36 70853834 42527.99 60622 MULTIPOLYGON (((-87.66707 4... ## 5 37 99039621 47970.14 60651 MULTIPOLYGON (((-87.70656 4... ## 6 38 23506056 34689.35 60611 MULTIPOLYGON (((-87.61401 4... Next, merge on zip code ID. The key in the Chi_Zips object is zip, whereas the key for the COVID data is ZIP.code. Chi_Zipsf &lt;- merge(Chi_Zips, COVID.39f, by.x = &quot;zip&quot;, by.y = &quot;ZIP.Code&quot;) head(Chi_Zipsf) ## Simple feature collection with 6 features and 5 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -87.63999 ymin: 41.85317 xmax: -87.60246 ymax: 41.88913 ## CRS: 4326 ## zip objectid shape_area shape_len Case.Rate...Cumulative ## 1 60601 27 9166246 19804.58 1451.4 ## 2 60602 26 4847125 14448.17 1688.1 ## 3 60603 19 4560229 13672.68 1107.3 ## 4 60604 48 4294902 12245.81 3964.2 ## 5 60605 20 36301276 37973.35 1420.8 ## 6 60606 31 6766411 12040.44 2289.6 ## geometry ## 1 MULTIPOLYGON (((-87.62271 4... ## 2 MULTIPOLYGON (((-87.60997 4... ## 3 MULTIPOLYGON (((-87.61633 4... ## 4 MULTIPOLYGON (((-87.63376 4... ## 5 MULTIPOLYGON (((-87.62064 4... ## 6 MULTIPOLYGON (((-87.63397 4... 2.3 Quantile Maps Starting with a “classic epi” approach, let’s look at case rates as quantiles. We use the tmap library, and update the choropleth data classification using the “style” parameter. We use the Blue-Purple palette, or BuPu, from Colorbrewer. library(tmap) tm_shape(Chi_Zipsf ) + tm_polygons(&quot;Case.Rate...Cumulative&quot;, style=&quot;quantile&quot;, pal=&quot;BuPu&quot;, title = &quot;COVID Case Rate&quot;) Let’s try tertiles: tm_shape(Chi_Zipsf ) + tm_polygons(&quot;Case.Rate...Cumulative&quot;, style=&quot;quantile&quot;, n=3, pal=&quot;BuPu&quot;, title = &quot;COVID Case Rate&quot;) 2.4 Standard Deviation Maps While quantiles are a nice start, let’s classify using a standard deviation map. Standard deviation is a statistical technique type of map based on how much the data differs from the mean. tm_shape(Chi_Zipsf ) + tm_polygons(&quot;Case.Rate...Cumulative&quot;, style=&quot;sd&quot;, pal=&quot;BuPu&quot;, title = &quot;COVID Case Rate&quot;) 2.5 Jenks Maps Another approach of data classification is natural breaks, or jenks. This approach looks for “natural breaks” in the data using a univariate clustering algorithm. tm_shape(Chi_Zipsf ) + tm_polygons(&quot;Case.Rate...Cumulative&quot;, style=&quot;jenks&quot;, pal=&quot;BuPu&quot;, title = &quot;COVID Case Rate&quot;) The first bin doesn’t seem very intuitive. Let’s try 4 bins instead of 5 by changing the n parameter. In this version, we’ll also had a histogram and scale bar, and move the legend outside the frame to make it easier to view. tm_shape(Chi_Zipsf ) + tm_polygons(&quot;Case.Rate...Cumulative&quot;, style=&quot;jenks&quot;, pal=&quot;BuPu&quot;, legend.hist=T, n=4, title = &quot;COVID Case Rate&quot;, ) + tm_scale_bar(position = &quot;left&quot;) + tm_layout(legend.outside = TRUE, legend.outside.position = &quot;right&quot;) 2.6 Integrate More Data To explore potential disparities in COVID health outcomes, let’s bring in demographic, racial, ethnic data from the OEPS project. This data is orginally sources from the American Community Survey 2018 5-year estimate. CensusVar &lt;- read.csv(&quot;data/DS01_Z.csv&quot;) head(CensusVar) ## ZCTA year totPopE whiteP blackP amIndP asianP pacIsP otherP hispP noHSP ## 1 35004 2018 11762 84.39 13.09 0.00 0.94 0.00 1.57 0.94 5.52 ## 2 35005 2018 7528 55.22 42.44 0.64 0.00 0.15 1.55 1.37 17.48 ## 3 35006 2018 2927 96.04 3.21 0.27 0.00 0.00 0.48 0.00 14.44 ## 4 35007 2018 26328 73.83 13.75 0.04 1.33 0.02 11.01 11.11 12.41 ## 5 35010 2018 20625 63.07 32.43 0.39 0.65 0.00 3.45 4.10 22.00 ## 6 35013 2018 40 100.00 0.00 0.00 0.00 0.00 0.00 100.00 100.00 ## age0_4 age5_14 age15_19 age20_24 age15_44 age45_49 age50_54 age55_59 age60_64 ## 1 787 1950 457 746 4552 662 541 776 832 ## 2 511 1055 455 277 2429 580 469 560 552 ## 3 161 413 141 203 878 129 193 316 278 ## 4 1891 4161 1619 1400 9947 1993 2067 1713 1315 ## 5 1013 2647 1383 1087 7036 1418 1545 1510 1341 ## 6 0 0 0 0 13 8 19 0 0 ## ageOv65 ageOv18 age18_64 a15_24P und45P ovr65P disbP ## 1 1662 8820 7158 10.23 61.97 14.13 12.7 ## 2 1372 5691 4319 9.72 53.07 18.23 23.2 ## 3 559 2308 1749 11.75 49.61 19.10 20.9 ## 4 3241 19178 15937 11.47 60.77 12.31 13.5 ## 5 4115 16142 12027 11.98 51.86 19.95 19.6 ## 6 0 40 40 0.00 32.50 0.00 0.0 Merge to our master Zip Code dataset. Chi_Zipsf &lt;- merge(Chi_Zipsf, CensusVar, by.x = &quot;zip&quot;, by.y = &quot;ZCTA&quot;) head(Chi_Zipsf) ## Simple feature collection with 6 features and 31 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -87.63999 ymin: 41.85317 xmax: -87.60246 ymax: 41.88913 ## CRS: 4326 ## zip objectid shape_area shape_len Case.Rate...Cumulative year totPopE whiteP ## 1 60601 27 9166246 19804.58 1451.4 2018 14675 74.17 ## 2 60602 26 4847125 14448.17 1688.1 2018 1244 68.17 ## 3 60603 19 4560229 13672.68 1107.3 2018 1174 63.46 ## 4 60604 48 4294902 12245.81 3964.2 2018 782 63.43 ## 5 60605 20 36301276 37973.35 1420.8 2018 27519 61.20 ## 6 60606 31 6766411 12040.44 2289.6 2018 3101 72.75 ## blackP amIndP asianP pacIsP otherP hispP noHSP age0_4 age5_14 age15_19 age20_24 ## 1 5.57 0.45 18.00 0.00 1.81 8.68 0.00 550 156 907 909 ## 2 3.78 5.31 19.45 0.00 3.30 6.51 0.00 61 87 18 91 ## 3 3.24 0.00 27.60 0.00 5.71 9.80 0.00 13 43 179 172 ## 4 5.63 0.00 29.67 0.00 1.28 4.35 0.00 12 7 52 168 ## 5 17.18 0.18 16.10 0.03 5.31 5.84 2.39 837 1279 2172 2282 ## 6 2.35 0.00 18.09 0.00 6.80 6.29 0.73 57 44 0 139 ## age15_44 age45_49 age50_54 age55_59 age60_64 ageOv65 ageOv18 age18_64 a15_24P ## 1 8726 976 1009 324 859 2075 13855 11780 12.37 ## 2 987 46 53 0 5 5 1095 1090 8.76 ## 3 684 75 47 150 50 112 1118 1006 29.90 ## 4 450 27 47 54 92 93 744 651 28.13 ## 5 16364 1766 1520 1824 1360 2569 25259 22690 16.19 ## 6 1863 213 153 168 172 431 3000 2569 4.48 ## und45P ovr65P disbP geometry ## 1 64.27 14.14 6.4 MULTIPOLYGON (((-87.62271 4... ## 2 91.24 0.40 0.2 MULTIPOLYGON (((-87.60997 4... ## 3 63.03 9.54 7.3 MULTIPOLYGON (((-87.61633 4... ## 4 59.97 11.89 4.1 MULTIPOLYGON (((-87.63376 4... ## 5 67.15 9.34 5.3 MULTIPOLYGON (((-87.62064 4... ## 6 63.33 13.90 1.9 MULTIPOLYGON (((-87.63397 4... 2.7 Thematic Map Panel COVID &lt;- tm_shape(Chi_Zipsf) + tm_fill(&quot;Case.Rate...Cumulative&quot;, style=&quot;jenks&quot;, pal=&quot;BuPu&quot;, n=4, title = &quot;COVID Rt&quot;) + tm_layout(frame = F) Senior &lt;- tm_shape(Chi_Zipsf) + tm_fill(&quot;ovr65P&quot;, style=&quot;jenks&quot;, pal=&quot;BuPu&quot;, n=4) + tm_layout(frame = F) NoHS &lt;- tm_shape(Chi_Zipsf) + tm_fill(&quot;noHSP&quot;, style=&quot;jenks&quot;, pal=&quot;BuPu&quot;, n=4) + tm_layout(frame = F) BlkP &lt;- tm_shape(Chi_Zipsf) + tm_fill(&quot;blackP&quot;, style=&quot;jenks&quot;, pal=&quot;BuPu&quot;, n=4) + tm_layout(frame = F) Latnx &lt;- tm_shape(Chi_Zipsf) + tm_fill(&quot;hispP&quot;, style=&quot;jenks&quot;, pal=&quot;BuPu&quot;, n=4) + tm_layout(frame = F) WhiP &lt;- tm_shape(Chi_Zipsf) + tm_fill(&quot;whiteP&quot;, style=&quot;jenks&quot;, pal=&quot;BuPu&quot;, n=4) + tm_layout(frame = F) tmap_arrange(COVID, Senior, NoHS, BlkP, Latnx, WhiP) ## Legend labels were too wide. The labels have been resized to 0.63, 0.55, 0.55, 0.55. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger. ## Legend labels were too wide. The labels have been resized to 0.66, 0.60, 0.55, 0.55. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger. ## Legend labels were too wide. The labels have been resized to 0.66, 0.60, 0.55, 0.55. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger. ## Legend labels were too wide. The labels have been resized to 0.60, 0.55, 0.55, 0.55. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger. ## Legend labels were too wide. The labels have been resized to 0.60, 0.55, 0.55, 0.55. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger. ## Legend labels were too wide. The labels have been resized to 0.60, 0.55, 0.55, 0.55. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger. 2.8 Write Data st_write(Chi_Zipsf, &quot;data/ChiZipMaster1.geojson&quot;, driver = &quot;GeoJSON&quot;, append= FALSE) ## Warning in CPL_write_ogr(obj, dsn, layer, driver, as.character(dataset_options), : ## GDAL Error 6: DeleteLayer() not supported by this dataset. ## Deleting layer not supported by driver `GeoJSON&#39; ## Deleting layer `ChiZipMaster1&#39; failed ## Writing layer `ChiZipMaster1&#39; to data source ## `data/ChiZipMaster1.geojson&#39; using driver `GeoJSON&#39; ## Updating existing layer ChiZipMaster1 ## Writing 60 features with 31 fields and geometry type Multi Polygon. More Resources For choropleth mapping in R: https://spatialanalysis.github.io/lab_tutorials/4_R_Mapping.html "],
["03-overlaypoints.html", "3 Adding Resources 3.1 Geocode 3.2 Convert to Spatial Data 3.3 Basic Map of Points 3.4 Overlay Points &amp; Style 3.5 Integrate More Data 3.6 Graduated Symbology 3.7 Style Final Map", " 3 Adding Resources 3.1 Geocode First we load the tidygeocoder to get our geocoding done. Note, this uses the interent to process, so is not suitable for HIPPA protected data like individual, living person addresses. library(tidygeocoder) Let’s read in and inspect data for methadone (evidenes based medication for opioid use disorder) providers. These addresses were made available by SAMSHA. methadoneClinics &lt;- read.csv(&quot;data/chicago_methadone_nogeometry.csv&quot;) head(methadoneClinics) ## X Name ## 1 1 Chicago Treatment and Counseling Center, Inc. ## 2 2 Sundace Methadone Treatment Center, LLC ## 3 3 Soft Landing Interventions/DBA Symetria Recovery of Lakeview ## 4 4 PDSSC - Chicago, Inc. ## 5 5 Center for Addictive Problems, Inc. ## 6 6 Family Guidance Centers, Inc. ## Address City State Zip ## 1 4453 North Broadway st. Chicago IL 60640 ## 2 4545 North Broadway St. Chicago IL 60640 ## 3 3934 N. Lincoln Ave. Chicago IL 60613 ## 4 2260 N. Elston Ave. Chicago IL 60614 ## 5 609 N. Wells St. Chicago IL 60654 ## 6 310 W. Chicago Ave. Chicago IL 60654 Let’s geocode one address first, just to make sure our system is working. We’ll use the “cascade” method which use the US Census and OpenStreetMap geocoders. sample &lt;- geo(&quot;2260 N. Elston Ave. Chicago, IL&quot;, lat = latitude, long = longitude, method = &#39;cascade&#39;) head(sample) ## # A tibble: 1 x 4 ## address latitude longitude geo_method ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 2260 N. Elston Ave. Chicago, IL 41.9 -87.7 census As we prepare for geocoding, check out the structure of the dataset. Do we need to change anything? The data should be a character to be read properly. str(methadoneClinics) ## &#39;data.frame&#39;: 27 obs. of 6 variables: ## $ X : int 1 2 3 4 5 6 7 8 9 10 ... ## $ Name : Factor w/ 25 levels &quot;*&quot;,&quot;A Rincon Family Services&quot;,..: 5 25 23 21 3 8 2 1 14 24 ... ## $ Address: Factor w/ 27 levels &quot;110 E. 79th St.&quot;,..: 20 21 17 6 23 10 16 3 5 8 ... ## $ City : Factor w/ 1 level &quot;Chicago&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ State : Factor w/ 1 level &quot;IL&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Zip : int 60640 60640 60613 60614 60654 60654 60651 60607 60607 60616 ... We need to clean the data a bit. We’ll add a new column for full address, as required by the geocoding service. When you use a geocoding service, be sure to read the documentation and understand how the data needs to be formatted for input. methadoneClinics$fullAdd &lt;- paste(as.character(methadoneClinics$Address), as.character(methadoneClinics$City), as.character(methadoneClinics$State), as.character(methadoneClinics$Zip)) We’re ready to go! Batch geocode with one function: geoCodedClinics &lt;- geocode(methadoneClinics, address = &#39;fullAdd&#39;, lat = latitude, long = longitude, method = &#39;cascade&#39;) head(geoCodedClinics) ## # A tibble: 6 x 10 ## X Name Address City State Zip fullAdd latitude longitude geo_method ## &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 Chicago… 4453 No… Chic… IL 60640 4453 No… NA NA osm ## 2 2 Sundace… 4545 No… Chic… IL 60640 4545 No… NA NA osm ## 3 3 Soft La… 3934 N.… Chic… IL 60613 3934 N.… 42.0 -87.7 census ## 4 4 PDSSC -… 2260 N.… Chic… IL 60614 2260 N.… 41.9 -87.7 census ## 5 5 Center … 609 N. … Chic… IL 60654 609 N. … 41.9 -87.6 census ## 6 6 Family … 310 W. … Chic… IL 60654 310 W. … 41.9 -87.6 census There were two that didn’t geocode correctly. You can either inspect further, change the addresses, searching the address and pulling the lat/long using Google Maps and inputting manually, or omit. For this exercise we’ll just omit the two clinics that didn’t geocode correctly. geoCodedClinics2 &lt;- na.omit(geoCodedClinics) 3.2 Convert to Spatial Data This is not spatial data yet! To convert a static CSV file to spatial data, we use the powerful st_as-sf function from sf. Indicate the x,y parameters (longitude, latitude) and the coordinate reference system used. Our geocoding service used the standard EPSG:4326, so we input that here. library(sf) methadoneSf &lt;- st_as_sf(geoCodedClinics2, coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) 3.3 Basic Map of Points For a really simple basemap of points – to ensure they were geocoded and converted to spatial data correctly, we use tmap. We’ll use the interactive version to view. library(tmap) tmap_mode(&quot;view&quot;) ## tmap mode set to interactive viewing tm_shape(methadoneSf) + tm_dots() ## Warning in `$.crs`(gm$shape.master_crs, &quot;proj4string&quot;): CRS uses proj4string, ## which is deprecated. If your points didn’t plot correctly: Did you flip the longitude/latitude values? Did you input the correct CRS? Those two issues are the most common errors. 3.4 Overlay Points &amp; Style Let’s add our zip code map from the previous module. First load the data, then overlay. Chi_Zipsf &lt;- st_read(&quot;data/ChiZipMaster1.geojson&quot;) ## Reading layer `ChiZipMaster1&#39; from data source ## `/Users/maryniakolak/code/Intro2RSpatialMed/data/ChiZipMaster1.geojson&#39; ## using driver `GeoJSON&#39; ## Simple feature collection with 240 features and 31 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -87.87596 ymin: 41.64454 xmax: -87.52414 ymax: 42.02304 ## CRS: 4326 With this overlay, we’ll add a “hack” to include the methadone clinic points in a legend. tmap_mode(&quot;plot&quot;) ## tmap mode set to plotting ## 1st layer (gets plotted first) tm_shape(Chi_Zipsf) + tm_fill(&quot;Case.Rate...Cumulative&quot;, style=&quot;jenks&quot;, pal=&quot;BuPu&quot;, n=4, title = &quot;COVID Rt&quot;) + ## 2nd layer (overlay) tm_shape(methadoneSf) + tm_dots(size = 0.2, col = &quot;gray20&quot;) + tm_add_legend(&quot;symbol&quot;, col = &quot;gray20&quot;, size = .2, labels = &quot;Methadone MOUD&quot;) + tm_layout(legend.outside = TRUE, legend.outside.position = &quot;right&quot;, title.snap.to.legend = TRUE) 3.5 Integrate More Data AffHousing &lt;- read.csv(&quot;data/Affordable_Rental_Housing_Developments.csv&quot;) head(AffHousing) ## Community.Area.Name Community.Area.Number Property.Type ## 1 Englewood 68 Veterans ## 2 Rogers Park 1 Senior ## 3 Uptown 3 ARO ## 4 Edgewater 77 Senior ## 5 Roseland 49 Supportive Housing ## 6 Humboldt Park 23 Multifamily ## Property.Name Address Zip.Code Phone.Number ## 1 Hope Manor Village 5900-6100 S. Green/Peoria/Sangamon 60621 312-564-2393 ## 2 Morse Senior Apts. 6928 N. Wayne Ave. 60626 312-602-6207 ## 3 The Draper 5050 N. Broadway 60640 312-818-1722 ## 4 Pomeroy Apts. 5650 N. Kenmore Ave. 60660 773-275-7820 ## 5 Wentworth Commons 11045 S. Wentworth Ave. 60628 773-568-7804 ## 6 Nelson Mandela Apts. 607 N. Sawyer Ave. 60624 773-227-6332 ## Management.Company Units X.Coordinate Y.Coordinate Latitude ## 1 Volunteers of America Illinois 36 NA NA NA ## 2 Morse Urban Dev. 44 1165844 1946059 42.00757 ## 3 Flats LLC 35 1167357 1933882 41.97413 ## 4 Habitat Company 198 1168181 1937918 41.98519 ## 5 Mercy Housing Lakefront 50 1176951 1831516 41.69302 ## 6 Bickerdike Apts. 6 1154640 1903912 41.89215 ## Longitude Location ## 1 NA ## 2 -87.66517 (42.0075737709331, -87.6651711448293) ## 3 -87.65996 (41.9741295261027, -87.6599553011627) ## 4 -87.65681 (41.9851867755403, -87.656808676983) ## 5 -87.62777 (41.6930159120977, -87.6277673462214) ## 6 -87.70753 (41.8921534052465, -87.7075265659001) AffHousing &lt;- na.omit(AffHousing) str(AffHousing) ## &#39;data.frame&#39;: 487 obs. of 14 variables: ## $ Community.Area.Name : Factor w/ 65 levels &quot;Albany Park&quot;,..: 49 55 17 50 25 22 65 45 45 37 ... ## $ Community.Area.Number: int 1 3 77 49 23 38 42 36 36 8 ... ## $ Property.Type : Factor w/ 26 levels &quot;65+/Supportive&quot;,..: 13 2 13 19 8 8 8 8 13 19 ... ## $ Property.Name : Factor w/ 394 levels &quot;1038 N. Ashland&quot;,..: 214 338 257 376 218 186 109 235 234 348 ... ## $ Address : Factor w/ 478 levels &quot;10 N. Hamlin Ave.&quot;,..: 424 348 367 17 384 298 71 279 275 64 ... ## $ Zip.Code : int 60626 60640 60660 60628 60624 60653 60637 60653 60653 60622 ... ## $ Phone.Number : Factor w/ 326 levels &quot;217-779-5697&quot;,..: 57 78 134 221 111 232 225 164 164 32 ... ## $ Management.Company : Factor w/ 200 levels &quot;@properties&quot;,..: 112 57 66 104 17 80 176 167 169 74 ... ## $ Units : int 44 35 198 50 6 71 67 534 148 40 ... ## $ X.Coordinate : num 1165844 1167357 1168181 1176951 1154640 ... ## $ Y.Coordinate : num 1946059 1933882 1937918 1831516 1903912 ... ## $ Latitude : num 42 42 42 41.7 41.9 ... ## $ Longitude : num -87.7 -87.7 -87.7 -87.6 -87.7 ... ## $ Location : Factor w/ 477 levels &quot;&quot;,&quot;(41.648457411436, -87.5401231660406)&quot;,..: 475 455 462 8 289 122 67 147 151 328 ... ## - attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int 1 ## ..- attr(*, &quot;names&quot;)= chr &quot;1&quot; AffHousingSf &lt;- st_as_sf(AffHousing, coords = c(&quot;Longitude&quot;, &quot;Latitude&quot;), crs = 4326) tm_shape(AffHousingSf) + tm_dots() tm_shape(Chi_Zipsf) + tm_polygons(col = &quot;gray80&quot;) + tm_shape(AffHousingSf) + tm_bubbles(&quot;Units&quot;, col = &quot;purple&quot;) str(AffHousingSf) ## Classes &#39;sf&#39; and &#39;data.frame&#39;: 487 obs. of 13 variables: ## $ Community.Area.Name : Factor w/ 65 levels &quot;Albany Park&quot;,..: 49 55 17 50 25 22 65 45 45 37 ... ## $ Community.Area.Number: int 1 3 77 49 23 38 42 36 36 8 ... ## $ Property.Type : Factor w/ 26 levels &quot;65+/Supportive&quot;,..: 13 2 13 19 8 8 8 8 13 19 ... ## $ Property.Name : Factor w/ 394 levels &quot;1038 N. Ashland&quot;,..: 214 338 257 376 218 186 109 235 234 348 ... ## $ Address : Factor w/ 478 levels &quot;10 N. Hamlin Ave.&quot;,..: 424 348 367 17 384 298 71 279 275 64 ... ## $ Zip.Code : int 60626 60640 60660 60628 60624 60653 60637 60653 60653 60622 ... ## $ Phone.Number : Factor w/ 326 levels &quot;217-779-5697&quot;,..: 57 78 134 221 111 232 225 164 164 32 ... ## $ Management.Company : Factor w/ 200 levels &quot;@properties&quot;,..: 112 57 66 104 17 80 176 167 169 74 ... ## $ Units : int 44 35 198 50 6 71 67 534 148 40 ... ## $ X.Coordinate : num 1165844 1167357 1168181 1176951 1154640 ... ## $ Y.Coordinate : num 1946059 1933882 1937918 1831516 1903912 ... ## $ Location : Factor w/ 477 levels &quot;&quot;,&quot;(41.648457411436, -87.5401231660406)&quot;,..: 475 455 462 8 289 122 67 147 151 328 ... ## $ geometry :sfc_POINT of length 487; first list element: &#39;XY&#39; num -87.7 42 ## - attr(*, &quot;sf_column&quot;)= chr &quot;geometry&quot; ## - attr(*, &quot;agr&quot;)= Factor w/ 3 levels &quot;constant&quot;,&quot;aggregate&quot;,..: NA NA NA NA NA NA NA NA NA NA ... ## ..- attr(*, &quot;names&quot;)= chr &quot;Community.Area.Name&quot; &quot;Community.Area.Number&quot; &quot;Property.Type&quot; &quot;Property.Name&quot; ... tm_shape(Chi_Zipsf) + tm_polygons(col = &quot;gray80&quot;) + tm_shape(AffHousingSf) + tm_bubbles(&quot;Units&quot;, style = &quot;pretty&quot;) tm_shape(Chi_Zipsf) + tm_fill(&quot;Case.Rate...Cumulative&quot;, style=&quot;jenks&quot;, pal=&quot;BuPu&quot;, n=4, title = &quot;COVID Rt&quot;) + tm_text(&quot;zip&quot;, size = 0.7) + tm_shape(AffHousingSf) + tm_bubbles(&quot;Units&quot;) + tm_shape(methadoneSf) + tm_dots(size = 0.2, col = &quot;gray20&quot;) + tm_add_legend(&quot;symbol&quot;, col = &quot;gray20&quot;, size = .2, labels = &quot;Methadone MOUD&quot;) + tm_layout(legend.outside = TRUE, legend.outside.position = &quot;right&quot;) 3.6 Graduated Symbology 3.7 Style Final Map "],
["04-newsvar.html", "4 Calculate Spatial Metrics 4.1 Project Data 4.2 Buffer Data 4.3 Count resources by area 4.4 Count buffers by area 4.5 Integrate &amp; Explore", " 4 Calculate Spatial Metrics While we’ve generated some nice visualizations, we may need insights quantified as metrics at the neighborhood level. 4.1 Project Data First we need to switch to a projection that uses distance in feet or meters as a metric. Google search with the terms “EPSG”, your place of interest, and “feet.” For example, I searched “EPSG Illinois feet” and EPSG:3435 came up as a viable candidate. I’ll use that for our new, projected CRS. 4.2 Buffer Data Next, lets create a walkable buffer of one mile, or XX feet, for our MOUD provider locations. Individuals residing in places outside of that walkabile area may have difficulty accessing this medication during crises, like a pandemic. library(sf) # Load MOUD point data # Generate a buffer of one mile Now we can map the buffers: 4.3 Count resources by area Another way of understanding resource inequity is by thinking about how many resources exist in a neighborhood. If we didn’t have zip code areas in our location dataset, we could add them using a spatial join. # Load zip codes # Spatially join points to areas # Count how many points are in each area Is there a more “tidy” way to do that last step? Explore… Furthermore – you can reuse the coding snippet for different types of areas. For example, how many resources exist in each census tract, or block group? Etc. Another way to use this code is to spatially join individual patient locations to tracts… Once you have coordinates for each location, you’d convert to spatial data, and then use sf to spatially join. 4.4 Count buffers by area As the first stage already showed us, we know that MOUD locations are accessible up to one mile away. So a total number of resources by area may be too restrictive. Let’s calculated how many walkable service areas of MOUD clinics are in each tract. Or, how many buffers are in each tract… 4.5 Integrate &amp; Explore Let’s review: our master area file now has total number resources by zip and total number of walkable service areas by zip. Using your new spatial file, see if you can answer some of these quetions using various queries: Which zip codes have high rates of COVID and are not within a walking distance of a methadone MOUD? Which zip codes have worse access to affordable rental units, low educational rates, and less walkable access to MOUDs? What is the demographic and racial/ethnic characteristics of areas most vulnerable to high COVID rates in September 2020? "]
]
